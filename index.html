 <!DOCTYPE html>
<html>

<head>
	 <link rel="stylesheet" href="styles.css">
	 <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
	 <title>I Can See Clearly Now : Image Restoration via De-Raining</title> 
</head>

<body>
	<div class="content">
		
	<div id="paper-title">I Can See Clearly Now : Image Restoration via De-Raining</div>
	<br/><br/>

	
	<div class="details">	
		<div id="authors">
			<div id="porav">
				<div>Horia Porav</div>
				<div><a href="mailto:>horia@robots.ox.ac.uk"> <code>horia@robots.ox.ac.uk</code> </a></div>
			</div>
			<div id="bruls">
				<div>Tom Bruls</div>
				<div><a href="mailto:tomb@robots.ox.ac.uk"> <code>tomb@robots.ox.ac.uk</code> </a></div>
			</div>
			<div id="newman">
				<div>Paul Newman</div>
				<div><a href="mailto:pnewman@robots.ox.ac.uk"> <code>pnewman@robots.ox.ac.uk</code> </a></div>
			</div>
		</div>
		
		<div id="uni">University of Oxford</div>
	</div>	
	<br/><br/>


	<div class="chapter">Abstract</div>
	<div>We present a method for improving segmentation tasks on images affected by adherent rain drops and streaks. We introduce a novel stereo dataset recorded using a system that allows one lens to be affected by real water droplets while keeping the other lens clear. We train a denoising generator using this dataset and show that it is effective at removing the effect of real water droplets, in the context of image reconstruction and road marking segmentation. To further test our de-noising approach, we describe a method of adding computer-generated adherent water droplets and streaks to any images, and use this technique as a proxy to demonstrate the effectiveness of our model in the context of general semantic segmentation. We benchmark our results using the CamVid road marking segmentation dataset, Cityscapes semantic segmentation datasets and our own real-rain dataset, and  show significant improvement on all tasks.</div>
	<br/><br/>

	<iframe width="869" height="489" src="https://www.youtube.com/embed/P4a7C-V70Y8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


	<div class="chapter">Architecture</div>
	<br/>
	<img src="architecture.png" alt="Network architecture" class="center">
	<p class="description"><em>Fig 1. The internal architecture of our generator. We motivate the addition of additive skip connections by observing that much of the structure of the input image should be kept, along with illumination levels and fine details.</em></p> 
	<br/><br/>


	<div class="chapter">Rain-making device</div>
	<div></div>
	<br/>
	<img src="rainmaker.jpg" alt="Rainmaker" class="center">
	<p class="description"><em>Fig 2. Our small-baseline stereo camera setup. A bi-partite chamber with acrylic clear panels is placed in front of the lenses, with the left-hand section being kept dry at all times, while the right-hand section is sprayed with water droplets using an internal nozzle.</em></p>  
	<br/><br/>


	<div class="chapter">Dataset</div>
	<div>Version 1 of the dataset is available at <a href="https://drive.google.com/uc?id=12Y_Hz2Ha3MOK82ZNLk5DMPRzAnJM4XU0&export=download" download="Robotcar-rainy dataset">this link</a>!</div>
	<br/><br/>

	<div>
		<div class="row">
			<img src="examples/right/right_1535201998046127.png" alt="Example 1 (right)" class="example">
			<img src="examples/left/left_1535201998046127.png" alt="Example 1 (left)" class="example">
			<img src="examples/mask/mask_1535201998046127.png" alt="Example 1 (mask)" class="example">
		</div>
		<div class="row">
			<img src="examples/right/right_1535202904410922.png" alt="Example 2 (right)" class="example">
			<img src="examples/left/left_1535202904410922.png" alt="Example 2 (left)" class="example">
			<img src="examples/mask/mask_1535202904410922.png" alt="Example 2 (mask)" class="example">
		</div>
		<div class="row">
			<img src="examples/right/right_1535204767761702.png" alt="Example 3 (right)" class="example">
			<img src="examples/left/left_1535204767761702.png" alt="Example 3 (left)" class="example">
			<img src="examples/mask/mask_1535204767761702.png" alt="Example 1 (mask)" class="example">
		</div>
		<div class="row">
			<img src="examples/right/right_1535205189296408.png" alt="Example 4 (right)" class="example">
			<img src="examples/left/left_1535205189296408.png" alt="Example 4 (left)" class="example">
			<img src="examples/mask/mask_1535205189296408.png" alt="Example 4 (mask)" class="example">
		</div>
		<div class="legend">
			<p>a) Clear</p>
			<p>b) Rainy</p>
			<p>c) Ground truth</p>
		</div>
		<p class="description"><em>Fig 3. Examples from our dataset.</em></p> 
	</div>
	<br/><br/>
	


	<!-- <div class="chapter">Results</div>
	<div>Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aenean commodo ligula eget dolor. Aenean massa. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Donec quam felis, ultricies nec, pellentesque eu, pretium quis, sem. Nulla consequat massa quis enim. Donec pede justo, fringilla vel, aliquet nec, vulputate eget, arcu. In enim justo, rhoncus ut, imperdiet a, venenatis vitae, justo. Nullam dictum felis eu pede mollis pretium. Integer tincidunt. Cras dapibus. Vivamus elementum semper nisi. Aenean vulputate eleifend tellus. Aenean leo ligula, porttitor eu, consequat vitae, eleifend ac, enim. Aliquam lorem ante, dapibus in, viverra quis, feugiat a, tellus. Phasellus viverra nulla ut metus varius laoreet.</div>
	<br/>

	<div>
		<table>
			<tr>
			 	<th>Column 1</th>
			  	<th>Column 2</th>
			  	<th>Column 3</th>
			  	<th>Column 4</th>
			</tr>
			
			<tr>
			  	<td>Result 1</td>
			  	<td>Result 2</td>
			  	<td>Result 3</td>
			  	<td>Result 4</td>
			</tr>
			
			<tr>
			  	<td>Result 1</td>
			  	<td>Result 2</td>
			  	<td>Result 3</td>
			  	<td>Result 4</td>
			</tr>

			<tr>
			  	<td>Result 1</td>
			  	<td>Result 2</td>
			  	<td>Result 3</td>
			  	<td>Result 4</td>
			</tr>
		</table>
		<p class="description" id="results-table1"><em>Table 1. This is the description of the results.</em></p>
	</div> -->
	<br/><br/>

	<div class="chapter">References</div>
	<div>
		<p id="src1" class="clicked-ref">[1] D. Eigen, D. Krishnan, and R. Fergus. Restoring an image taken through a window covered with dirt or rain. In Proceedings of the IEEE International Conference on Computer Vision, pages 633-640, 2013.</p>
		<p id="src2" class="clicked-ref">[2] P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros. Image-to-image translation with conditional adversarial networks. arXiv preprint arXiv:1611.07004, 2016.</p>
		<p>[3] S. You, R. T. Tan, R. Kawakami, and K. Ikeuchi. Adherent raindrop detection and removal in video. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1035-1042, 2013.</p>
	</div>
	<br/><br/>


	</div>

	
</body>
</html> 
